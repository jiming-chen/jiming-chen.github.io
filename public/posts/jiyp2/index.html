<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>JIYP: Lessons Learned, Part 2 + Agent Architecture Report | Jiming Chen</title><meta name=keywords content><meta name=description content="Overview
This page will consist of two sections: a brief section on some lessons learned from this internship and a longer report describing in detail the agent architecture we used. For a detailed report on how our Django backend works, please see this.
Feel free to reach out on LinkedIn or email me at jc3579@cornell.edu if you have questions.
Lessons Learned, Part 2
In my first lessons learned post, I discussed how we used RAG in a specific way to address a specific use case: customizing advice based on referring doctor. This allowed us to have a different corpus of experts on whom to RAG based on which doctor was referring. However, this led us to one big issue: some more prolific experts, with more content on the internet, were overpowering the retrieval, even in areas not under their expertise. For example, if I asked a question about sleep, due to the sheer amount of his content, Mark Hyman&rsquo;s content would always come out on top over Matthew Walker, the actual sleep expert."><meta name=author content="Jiming Chen"><link rel=canonical href=https://jiming-chen.github.io/posts/jiyp2/><link crossorigin=anonymous href=/assets/css/stylesheet.0788e016f920508aef4b1850b916d4a2a5a89167bb733638fd43d8d85a28d7f4.css integrity="sha256-B4jgFvkgUIrvSxhQuRbUoqWokWe7czY4/UPY2Foo1/Q=" rel="preload stylesheet" as=style><link rel=icon href=https://jiming-chen.github.io/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jiming-chen.github.io/icons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jiming-chen.github.io/icons/favicon-32x32.png><link rel=apple-touch-icon href=https://jiming-chen.github.io/icons/apple-touch-icon.png><link rel=mask-icon href=https://jiming-chen.github.io/%3C/icons/apple-touch-icon.png%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://jiming-chen.github.io/posts/jiyp2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KTD621L9T6"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KTD621L9T6")</script><meta property="og:url" content="https://jiming-chen.github.io/posts/jiyp2/"><meta property="og:site_name" content="Jiming Chen"><meta property="og:title" content="JIYP: Lessons Learned, Part 2 + Agent Architecture Report"><meta property="og:description" content="Overview This page will consist of two sections: a brief section on some lessons learned from this internship and a longer report describing in detail the agent architecture we used. For a detailed report on how our Django backend works, please see this.
Feel free to reach out on LinkedIn or email me at jc3579@cornell.edu if you have questions.
Lessons Learned, Part 2 In my first lessons learned post, I discussed how we used RAG in a specific way to address a specific use case: customizing advice based on referring doctor. This allowed us to have a different corpus of experts on whom to RAG based on which doctor was referring. However, this led us to one big issue: some more prolific experts, with more content on the internet, were overpowering the retrieval, even in areas not under their expertise. For example, if I asked a question about sleep, due to the sheer amount of his content, Mark Hyman’s content would always come out on top over Matthew Walker, the actual sleep expert."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-10T23:08:31-07:00"><meta property="article:modified_time" content="2025-08-10T23:08:31-07:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="JIYP: Lessons Learned, Part 2 + Agent Architecture Report"><meta name=twitter:description content="Overview
This page will consist of two sections: a brief section on some lessons learned from this internship and a longer report describing in detail the agent architecture we used. For a detailed report on how our Django backend works, please see this.
Feel free to reach out on LinkedIn or email me at jc3579@cornell.edu if you have questions.
Lessons Learned, Part 2
In my first lessons learned post, I discussed how we used RAG in a specific way to address a specific use case: customizing advice based on referring doctor. This allowed us to have a different corpus of experts on whom to RAG based on which doctor was referring. However, this led us to one big issue: some more prolific experts, with more content on the internet, were overpowering the retrieval, even in areas not under their expertise. For example, if I asked a question about sleep, due to the sheer amount of his content, Mark Hyman&rsquo;s content would always come out on top over Matthew Walker, the actual sleep expert."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://jiming-chen.github.io/posts/"},{"@type":"ListItem","position":2,"name":"JIYP: Lessons Learned, Part 2 + Agent Architecture Report","item":"https://jiming-chen.github.io/posts/jiyp2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"JIYP: Lessons Learned, Part 2 + Agent Architecture Report","name":"JIYP: Lessons Learned, Part 2 \u002b Agent Architecture Report","description":"Overview This page will consist of two sections: a brief section on some lessons learned from this internship and a longer report describing in detail the agent architecture we used. For a detailed report on how our Django backend works, please see this.\nFeel free to reach out on LinkedIn or email me at jc3579@cornell.edu if you have questions.\nLessons Learned, Part 2 In my first lessons learned post, I discussed how we used RAG in a specific way to address a specific use case: customizing advice based on referring doctor. This allowed us to have a different corpus of experts on whom to RAG based on which doctor was referring. However, this led us to one big issue: some more prolific experts, with more content on the internet, were overpowering the retrieval, even in areas not under their expertise. For example, if I asked a question about sleep, due to the sheer amount of his content, Mark Hyman\u0026rsquo;s content would always come out on top over Matthew Walker, the actual sleep expert.\n","keywords":[],"articleBody":"Overview This page will consist of two sections: a brief section on some lessons learned from this internship and a longer report describing in detail the agent architecture we used. For a detailed report on how our Django backend works, please see this.\nFeel free to reach out on LinkedIn or email me at jc3579@cornell.edu if you have questions.\nLessons Learned, Part 2 In my first lessons learned post, I discussed how we used RAG in a specific way to address a specific use case: customizing advice based on referring doctor. This allowed us to have a different corpus of experts on whom to RAG based on which doctor was referring. However, this led us to one big issue: some more prolific experts, with more content on the internet, were overpowering the retrieval, even in areas not under their expertise. For example, if I asked a question about sleep, due to the sheer amount of his content, Mark Hyman’s content would always come out on top over Matthew Walker, the actual sleep expert.\nIn hindsight, the solution we arrived at sounds obvious, but it actually wasn’t the first thing we thought of. We first tried to exclude content that seemed extraneous or low-quality, but that didn’t guarantee that prolific experts would overpower more specialized ones.\nWhat we ended up doing was use a mapping from specialty to expert as well as a categorization of the question in order to filter to a specific source or set of sources. For example, if I asked “how much sleep should I be getting?”, the question would be categorized by an LLM as sleep, then the RAG would only retrieve chunks from the relevant sleep experts.\nAgent Architecture Report System Overview Jarvis In Your Pocket is an AI health companion you can chat with in plain English. You ask a question, Jarvis thinks through what tools it needs, and it replies while showing progress in real time. Under the hood, it keeps track of your conversation, saves important information to a database, and uses trustworthy sources when it gives health guidance.\nIn everyday use, Jarvis can log what you eat, help you choose meals at restaurants, answer health questions using sources your doctor would recognize, and update your profile without you filling out forms. Over time, the goal is to give Jarvis a deeper, privacy‑respecting memory so it can personalize help even more.\nCode Locations:\nMain chat endpoint: django_backend/health_api/views.py lines 1158-1200 Database models: django_backend/health_api/models.py lines 1-150 Frontend chat interface: django_backend/static/js/main.js lines 2330-2500 Core Architecture Code Locations:\nMain agent class: django_backend/health_api/unified_agent.py Chat endpoint: django_backend/health_api/views.py lines 1158-1200 Unified agent framework At the center is one “big loop” that receives your message, decides what to do, and produces an answer. We call this the unified agent loop, implemented in a UnifiedJarvisAgent class. Rather than hard‑coding every scenario, the agent chooses from small, focused functions (for example, “log food” or “search health info”) and composes them as needed.\nWhen Jarvis replies, it doesn’t wait until everything is finished. It streams its response in small chunks and triggers simple animations like “searching” before the response starts streaming so you can see progress. For conversation context, we use LangChain’s memory helpers to keep just the relevant recent messages, which helps Jarvis stay on topic without getting confused by very long histories.\nFig. 1. A diagram outlining the Jarvis' flow of data and action. It shows how a query results in database updates as well as a response. Key components in plain terms OpenAI models (GPT‑4o for web/tool use and GPT-4.1 for everything else) power the natural language understanding and the “function calling” that lets the model politely ask our code to do specific tasks. A PostgreSQL database, accessed through Django’s ORM, stores durable information like food logs and profile updates so the data survives app restarts and is easy to query later. A retrieval system known as RAG (retrieval‑augmented generation) uses a vector database (Pinecone) to look up relevant expert health sources before the model drafts an answer. In short: we search trusted documents first, queried both by health category and which doctor referred, then let the model write with those facts in view. A web search capability, called through OpenAI’s Responses API, lets Jarvis check the current web for things like live restaurant menus when static sources aren’t enough. Function Calling System Code Locations:\nFunction definitions: django_backend/health_api/unified_agent.py lines 86-250 Food logging: django_backend/health_api/unified_agent.py lines 423-523 Health info search: django_backend/health_api/unified_agent.py lines 324-422 Restaurant search: django_backend/health_api/unified_agent.py lines 524-623 The functions Jarvis can call (red box in diagram) Jarvis picks from a small set of clear tools:\nFood logging (log_food_intake): Given a sentence like “I ate a chicken burrito,” Jarvis identifies the food, estimates nutrition (calories, protein, etc.), and saves an entry for you. Health information (search_health_info): For questions like “Is omega‑3 helpful?”, Jarvis searches our expert sources first (via RAG) and then explains the finding in simple language. Restaurant menu analysis (search_restaurant_menu): When you name a restaurant and your goals, Jarvis looks up the current menu online and suggests items that meet your targets. Profile updates (update_user_profile): If you say “Change my weight goal,” Jarvis updates the profile fields in the database so future advice stays aligned. Of these functions, food logging and profile updates have side effects, namely updating the database accordingly. Food logging, as well as health information and restaurant menu searching, have return values which the main agent loop can use to appropriately formulate a response.\nHow a single query turns into an answer (important) When you send a message, the model first decides which function(s) are needed. We immediately show a small animation (like “searching the web”, this is the called “ripple” animation in the diagram) so you know work is happening. The code then runs the chosen function—sometimes alongside a database query/side effect—and collects the results. With that context in hand, the model drafts a conversational answer (red box in diagram). Finally, we stream that answer back to the app so you can read it as it appears, rather than waiting for a long pause and a single wall of text.\nAdvanced Features Code Locations:\nMemory management: django_backend/health_api/unified_agent.py lines 60-85 Context storage: django_backend/health_api/models.py lines 120-150 Memory and context management Jarvis remembers what happened in the current chat session so it can follow along naturally. We intentionally keep that memory “window” small so past details don’t overwhelm the current topic. We use LangChain’s ConversationBufferWindowMemory for this. On the output side, we apply a light formatting pass that fixes occasional spacing issues and keeps the tone friendly and conversational—more like a helpful health coach than a reference manual.\nPerformance Optimizations Making the loop fast without losing quality Because there is a single agent loop, we can optimize once and benefit everywhere. Web lookups go through a streamlined path that pairs GPT‑4.1 with the Responses API’s GPT-4o web tool, and the UI animations are triggered directly from function choices so feedback feels instant.\nWe also added “fast paths” for simple messages. If you say something like “thanks” or ask a very small follow‑up, Jarvis recognizes the pattern and responds quickly without spinning up unnecessary tools. This makes common interactions feel snappy. The trade‑off is that some complex answers may take a little longer, but overall the experience is both responsive and thorough.\nRestaurant Query Processing Example Real System Flow: “I am planning to have dinner at Teleferic Barcelona in Los Gatos tonight - what should I eat to stay under 1000 calories, get 60 grams of protein and 15 gms fiber” Here is what actually happens with a real example. Suppose you say: “I’m planning dinner at Teleferic Barcelona in Los Gatos—keep me under 1,000 calories with 60g protein and 15g fiber. What should I order?”\nStep 1: Understand the request and pick a tool The agent parses your message and recognizes it as a restaurant request. Using OpenAI’s “function calling” ability, it selects our search_restaurant_menu tool to find current menu items that match your goals. In code, this selection happens in UnifiedJarvisAgent.process_message_stream() and the function itself is defined in _define_functions().\nStep 2: Show progress right away Before the network request even finishes, the system streams a small token like “SEARCHING_WEB_ANIMATION” to the UI. That way, you immediately see that Jarvis is working, instead of staring at a blank screen.\nStep 3: Run the restaurant search The agent enriches your query with your calorie, protein, and fiber targets, then calls a helper (get_restaurant_web_search) that performs a web search for current menu details.\nStep 4: Use the web responsibly The web search helper builds a clear, structured prompt so the model knows exactly what to retrieve and how to format the results:\nsearch_prompt = f''' Find current menu items and nutrition info for {restaurant_name} that match: {query} Focus on: - 3-5 specific menu items with calorie/protein info - Healthy options that meet dietary goals - Include source links for each recommendation Format: \"Item name ([source](url)) - calories, protein\" Keep response concise. ''' It then calls OpenAI’s Responses API with the web search tool enabled, which lets the model use a browser‑like capability to gather live information:\nresponse = client.responses.create( model=\"gpt-4o\", input=search_prompt, tools=[{\"type\": \"web_search\"}] ) Step 5: Draft and stream the answer Once results come back, the agent weaves them into a short, friendly recommendation that cites sources. It streams the answer piece by piece so you can start reading without delay.\nIn conclusion, for this particular prompt, the data flow through the diagram is as follows: query =\u003e main agent loop =\u003e restaurant menu function =\u003e main agent loop =\u003e response.\nCode Locations:\nQuery processing: django_backend/health_api/unified_agent.py lines 284-404 Restaurant search: django_backend/health_api/rag_service.py lines 458-500 Function definitions: django_backend/health_api/unified_agent.py lines 86-110 Animation system: django_backend/health_api/unified_agent.py lines 714-728 Comprehensive Test Suite Code Locations:\nMain test file: django_backend/test_unified_agent_functions.py Test suite interface: django_backend/templates/admin/test_suite.html Overview We test Jarvis end‑to‑end using the same streaming pipeline the app uses in production. That means our tests are realistic: the agent calls the same functions, touches the same database, and produces the same kind of streaming messages users see. We don’t lock tests to a single “perfect” sentence—because language can vary—but we do check that the right functions run, data is saved correctly, and the final response reads sensibly. Specifically, we check response length, whether it RAGs and if so whether the category was correct, whether it logged food, and whether the ripple animation text was correct (which indicates whether the correct function was used).\nThe reason this is useful is because we have a set of behaviors we want Jarvis to adhere to, and at any time, we can run all of the tests to make sure that Jarvis does behave correctly. The test suite can also help with test-driven development. The test suite page is accessible at /system/admin/test-suite.\nTest Architecture Our main test file is django_backend/test_unified_agent_functions.py. Tests instantiate the real agent with streaming turned on. They operate against the same PostgreSQL database schema, but with isolated test users and session flags so no test runs pollute real chat history. Authentication uses dedicated accounts that mirror production, keeping the flow realistic.\nTest Categories We cover both one‑shot prompts and longer conversations.\n1) Single‑prompt function checks These tests send simple messages to validate each tool end to end. Examples include:\nFood logging: “I ate 2 eggs and bacon for breakfast.” Weight tracking: “I weigh 155 pounds today.” Health information: “Tell me about the benefits of omega‑3.” Profile updates: “Update my weight goal to gain muscle.” 2) Multi‑turn conversations These tests exercise memory and context. We simulate:\nProgressive food logging across a day, making sure totals add up. Health consultation flows with follow‑up questions and clarifications. Recipe recommendation chains that move from preferences to concrete dishes. Restaurant analysis that starts from location, narrows by cuisine, and ends with specific items. Test Execution Process Step 1: Start an isolated session Each test creates a unique session tied to a designated test user so data stays separate from real users:\n# Each test creates isolated session test_user = User.objects.get(username='test_user_agent_functions') session_id = f\"test_session_{int(time.time())}\" Step 2: Talk to the real streaming endpoint Rather than calling internal functions directly, tests hit the same streaming HTTP endpoint the app uses. That keeps behavior honest:\nresponse = requests.post('http://localhost:5000/api/chat/stream/', { 'message': test_message, 'user_id': test_user.id, 'session_id': session_id, 'test_mode': True # Flags as test chat }) Step 3: Check that the right things happened We verify that the expected function ran, that any database side effects (like new food entries) exist, and that the response reads clearly. Error paths are exercised too, to confirm the system fails gracefully and recovers.\nTest Data Validation Database verification Where a test implies a write—like logging food—we assert the database really changed:\n# Example: Food logging test verification food_entries = DailyFoodLog.objects.filter(user=test_user, date=today) assert len(food_entries) \u003e 0 assert any('eggs' in entry.food_name.lower() for entry in food_entries) Multi-Prompt Test Examples Health consultation flow Initial context: “I have diabetes and high blood pressure.” Follow‑up: “What breakfast foods should I avoid?” Clarification: “Is oatmeal okay for my conditions?” Expectation: The agent carries context across turns and tailors advice. Restaurant analysis chain Location: “I’m near downtown San Francisco.” Preference: “I want healthy Mexican food.” Goal: “Under 600 calories with high protein.” Expectation: The agent respects location and cuisine while meeting nutrition targets. Test Isolation and Cleanup Session management All test chats set test_mode=True, which hides them from normal history views and flags them for cleanup. Temporary session IDs prevent collisions.\nData isolation We use dedicated test users and tagging so it’s easy to find and remove any artifacts. This separation protects production data and keeps tests deterministic.\nPerformance Testing We measure not just whether Jarvis answers, but how quickly and reliably it does so. Streaming tests track how fast chunks arrive. Database tests time common operations to catch slow queries. Memory tests check that the conversation window stays bounded. Finally, we simulate multiple users at once to make sure the system remains stable under load.\nTest Reporting Our reports summarize pass rates, response quality checks, and correctness of side effects (like accurate database writes). We include timing data and resource usage to spot regressions early, and we keep detailed error logs to speed up debugging when something breaks.\nReal-World Simulation We write tests in the same everyday language people use and deliberately switch topics mid‑conversation to verify Jarvis keeps up. We feed it unclear or contradictory inputs to test recovery, and we include edge cases that are uncommon but realistic. The result is a test suite that mirrors real usage, not just happy‑path demos.\n","wordCount":"2410","inLanguage":"en","datePublished":"2025-08-10T23:08:31-07:00","dateModified":"2025-08-10T23:08:31-07:00","author":{"@type":"Person","name":"Jiming Chen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jiming-chen.github.io/posts/jiyp2/"},"publisher":{"@type":"Organization","name":"Jiming Chen","logo":{"@type":"ImageObject","url":"https://jiming-chen.github.io/icons/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jiming-chen.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://jiming-chen.github.io/icons/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://jiming-chen.github.io/about title="About Me"><span>About Me</span></a></li><li><a href=https://jiming-chen.github.io/projects/ title=Portfolio><span>Portfolio</span></a></li><li><a href=https://jiming-chen.github.io/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://jiming-chen.github.io/courses/ title="Course Notes"><span>Course Notes</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">JIYP: Lessons Learned, Part 2 + Agent Architecture Report</h1><div class=post-meta><span title='2025-08-10 23:08:31 -0700 -0700'>August 10, 2025</span>&nbsp;·&nbsp;Jiming Chen</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#system-overview>System Overview</a></li><li><a href=#core-architecture>Core Architecture</a><ul><li><a href=#unified-agent-framework>Unified agent framework</a></li><li><a href=#key-components-in-plain-terms>Key components in plain terms</a></li></ul></li><li><a href=#function-calling-system>Function Calling System</a><ul><li><a href=#the-functions-jarvis-can-call-red-box-in-diagram>The functions Jarvis can call (red box in diagram)</a></li><li><a href=#how-a-single-query-turns-into-an-answer-important>How a single query turns into an answer (important)</a></li></ul></li><li><a href=#advanced-features>Advanced Features</a><ul><li><a href=#memory-and-context-management>Memory and context management</a></li></ul></li><li><a href=#performance-optimizations>Performance Optimizations</a><ul><li><a href=#making-the-loop-fast-without-losing-quality>Making the loop fast without losing quality</a></li></ul></li><li><a href=#restaurant-query-processing-example>Restaurant Query Processing Example</a><ul><li><a href=#real-system-flow-i-am-planning-to-have-dinner-at-teleferic-barcelona-in-los-gatos-tonight---what-should-i-eat-to-stay-under-1000-calories-get-60-grams-of-protein-and-15-gms-fiber>Real System Flow: &ldquo;I am planning to have dinner at Teleferic Barcelona in Los Gatos tonight - what should I eat to stay under 1000 calories, get 60 grams of protein and 15 gms fiber&rdquo;</a></li></ul></li><li><a href=#comprehensive-test-suite>Comprehensive Test Suite</a><ul><li><a href=#overview-1>Overview</a></li><li><a href=#test-architecture>Test Architecture</a></li><li><a href=#test-categories>Test Categories</a></li><li><a href=#test-execution-process>Test Execution Process</a></li><li><a href=#test-data-validation>Test Data Validation</a></li><li><a href=#multi-prompt-test-examples>Multi-Prompt Test Examples</a></li><li><a href=#test-isolation-and-cleanup>Test Isolation and Cleanup</a></li><li><a href=#performance-testing>Performance Testing</a></li><li><a href=#test-reporting>Test Reporting</a></li><li><a href=#real-world-simulation>Real-World Simulation</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=overview>Overview<a hidden class=anchor aria-hidden=true href=#overview>#</a></h1><p>This page will consist of two sections: a brief section on some lessons learned from this internship and a longer report describing in detail the agent architecture we used. For a detailed report on how our Django backend works, please see <a href="https://docs.google.com/document/d/1ECKAXXHJE0lT7bwFxqrRb52l-gm_8zaF/edit?tab=t.0" rel=noopener target=_blank>this</a>.</p><p>Feel free to reach out on <a href=https://www.linkedin.com/in/jiming-chen/ rel=noopener target=_blank>LinkedIn</a> or email me at <code>jc3579@cornell.edu</code> if you have questions.</p><h1 id=lessons-learned-part-2>Lessons Learned, Part 2<a hidden class=anchor aria-hidden=true href=#lessons-learned-part-2>#</a></h1><p>In <a href=/posts/jiyp1/ rel=noopener target=_blank>my first lessons learned post</a>, I discussed how we used RAG in a specific way to address a specific use case: customizing advice based on referring doctor. This allowed us to have a different corpus of experts on whom to RAG based on which doctor was referring. However, this led us to one big issue: some more prolific experts, with more content on the internet, were overpowering the retrieval, even in areas not under their expertise. For example, if I asked a question about sleep, due to the sheer amount of his content, Mark Hyman&rsquo;s content would always come out on top over Matthew Walker, the actual sleep expert.</p><p>In hindsight, the solution we arrived at sounds obvious, but it actually wasn&rsquo;t the first thing we thought of. We first tried to exclude content that seemed extraneous or low-quality, but that didn&rsquo;t guarantee that prolific experts would overpower more specialized ones.</p><p>What we ended up doing was use a mapping from specialty to expert as well as a categorization of the question in order to filter to a specific source or set of sources. For example, if I asked &ldquo;how much sleep should I be getting?&rdquo;, the question would be categorized by an LLM as sleep, then the RAG would only retrieve chunks from the relevant sleep experts.</p><h1 id=agent-architecture-report>Agent Architecture Report<a hidden class=anchor aria-hidden=true href=#agent-architecture-report>#</a></h1><h2 id=system-overview>System Overview<a hidden class=anchor aria-hidden=true href=#system-overview>#</a></h2><p>Jarvis In Your Pocket is an AI health companion you can chat with in plain English. You ask a question, Jarvis thinks through what tools it needs, and it replies while showing progress in real time. Under the hood, it keeps track of your conversation, saves important information to a database, and uses trustworthy sources when it gives health guidance.</p><p>In everyday use, Jarvis can log what you eat, help you choose meals at restaurants, answer health questions using sources your doctor would recognize, and update your profile without you filling out forms. Over time, the goal is to give Jarvis a deeper, privacy‑respecting memory so it can personalize help even more.</p><p><strong>Code Locations:</strong></p><ul><li>Main chat endpoint: <code>django_backend/health_api/views.py</code> lines 1158-1200</li><li>Database models: <code>django_backend/health_api/models.py</code> lines 1-150</li><li>Frontend chat interface: <code>django_backend/static/js/main.js</code> lines 2330-2500</li></ul><h2 id=core-architecture>Core Architecture<a hidden class=anchor aria-hidden=true href=#core-architecture>#</a></h2><p><strong>Code Locations:</strong></p><ul><li>Main agent class: <code>django_backend/health_api/unified_agent.py</code></li><li>Chat endpoint: <code>django_backend/health_api/views.py</code> lines 1158-1200</li></ul><h3 id=unified-agent-framework>Unified agent framework<a hidden class=anchor aria-hidden=true href=#unified-agent-framework>#</a></h3><p>At the center is one “big loop” that receives your message, decides what to do, and produces an answer. We call this the unified agent loop, implemented in a <code>UnifiedJarvisAgent</code> class. Rather than hard‑coding every scenario, the agent chooses from small, focused functions (for example, “log food” or “search health info”) and composes them as needed.</p><p>When Jarvis replies, it doesn’t wait until everything is finished. It streams its response in small chunks and triggers simple animations like “searching” before the response starts streaming so you can see progress. For conversation context, we use LangChain’s memory helpers to keep just the relevant recent messages, which helps Jarvis stay on topic without getting confused by very long histories.</p><img src=/posts/jarvisdiagram.png alt="Code translation" width=80% class=center><figcaption>Fig. 1. A diagram outlining the Jarvis' flow of data and action. It shows how a query results in database updates as well as a response.</figcaption><h3 id=key-components-in-plain-terms>Key components in plain terms<a hidden class=anchor aria-hidden=true href=#key-components-in-plain-terms>#</a></h3><ul><li>OpenAI models (GPT‑4o for web/tool use and GPT-4.1 for everything else) power the natural language understanding and the “function calling” that lets the model politely ask our code to do specific tasks.</li><li>A PostgreSQL database, accessed through Django’s ORM, stores durable information like food logs and profile updates so the data survives app restarts and is easy to query later.</li><li>A retrieval system known as RAG (retrieval‑augmented generation) uses a vector database (Pinecone) to look up relevant expert health sources before the model drafts an answer. In short: we search trusted documents first, queried both by health category and which doctor referred, then let the model write with those facts in view.</li><li>A web search capability, called through OpenAI’s Responses API, lets Jarvis check the current web for things like live restaurant menus when static sources aren’t enough.</li></ul><h2 id=function-calling-system>Function Calling System<a hidden class=anchor aria-hidden=true href=#function-calling-system>#</a></h2><p><strong>Code Locations:</strong></p><ul><li>Function definitions: <code>django_backend/health_api/unified_agent.py</code> lines 86-250</li><li>Food logging: <code>django_backend/health_api/unified_agent.py</code> lines 423-523</li><li>Health info search: <code>django_backend/health_api/unified_agent.py</code> lines 324-422</li><li>Restaurant search: <code>django_backend/health_api/unified_agent.py</code> lines 524-623</li></ul><h3 id=the-functions-jarvis-can-call-red-box-in-diagram>The functions Jarvis can call (red box in diagram)<a hidden class=anchor aria-hidden=true href=#the-functions-jarvis-can-call-red-box-in-diagram>#</a></h3><p>Jarvis picks from a small set of clear tools:</p><ul><li>Food logging (<code>log_food_intake</code>): Given a sentence like “I ate a chicken burrito,” Jarvis identifies the food, estimates nutrition (calories, protein, etc.), and saves an entry for you.</li><li>Health information (<code>search_health_info</code>): For questions like “Is omega‑3 helpful?”, Jarvis searches our expert sources first (via RAG) and then explains the finding in simple language.</li><li>Restaurant menu analysis (<code>search_restaurant_menu</code>): When you name a restaurant and your goals, Jarvis looks up the current menu online and suggests items that meet your targets.</li><li>Profile updates (<code>update_user_profile</code>): If you say “Change my weight goal,” Jarvis updates the profile fields in the database so future advice stays aligned.</li></ul><p>Of these functions, food logging and profile updates have side effects, namely updating the database accordingly. Food logging, as well as health information and restaurant menu searching, have return values which the main agent loop can use to appropriately formulate a response.</p><h3 id=how-a-single-query-turns-into-an-answer-important>How a single query turns into an answer (important)<a hidden class=anchor aria-hidden=true href=#how-a-single-query-turns-into-an-answer-important>#</a></h3><p>When you send a message, the model first decides which function(s) are needed. We immediately show a small animation (like “searching the web”, this is the called &ldquo;ripple&rdquo; animation in the diagram) so you know work is happening. The code then runs the chosen function—sometimes alongside a database query/side effect—and collects the results. With that context in hand, the model drafts a conversational answer (red box in diagram). Finally, we stream that answer back to the app so you can read it as it appears, rather than waiting for a long pause and a single wall of text.</p><h2 id=advanced-features>Advanced Features<a hidden class=anchor aria-hidden=true href=#advanced-features>#</a></h2><p><strong>Code Locations:</strong></p><ul><li>Memory management: <code>django_backend/health_api/unified_agent.py</code> lines 60-85</li><li>Context storage: <code>django_backend/health_api/models.py</code> lines 120-150</li></ul><h3 id=memory-and-context-management>Memory and context management<a hidden class=anchor aria-hidden=true href=#memory-and-context-management>#</a></h3><p>Jarvis remembers what happened in the current chat session so it can follow along naturally. We intentionally keep that memory “window” small so past details don’t overwhelm the current topic. We use LangChain’s ConversationBufferWindowMemory for this. On the output side, we apply a light formatting pass that fixes occasional spacing issues and keeps the tone friendly and conversational—more like a helpful health coach than a reference manual.</p><h2 id=performance-optimizations>Performance Optimizations<a hidden class=anchor aria-hidden=true href=#performance-optimizations>#</a></h2><h3 id=making-the-loop-fast-without-losing-quality>Making the loop fast without losing quality<a hidden class=anchor aria-hidden=true href=#making-the-loop-fast-without-losing-quality>#</a></h3><p>Because there is a single agent loop, we can optimize once and benefit everywhere. Web lookups go through a streamlined path that pairs GPT‑4.1 with the Responses API’s GPT-4o web tool, and the UI animations are triggered directly from function choices so feedback feels instant.</p><p>We also added “fast paths” for simple messages. If you say something like “thanks” or ask a very small follow‑up, Jarvis recognizes the pattern and responds quickly without spinning up unnecessary tools. This makes common interactions feel snappy. The trade‑off is that some complex answers may take a little longer, but overall the experience is both responsive and thorough.</p><h2 id=restaurant-query-processing-example>Restaurant Query Processing Example<a hidden class=anchor aria-hidden=true href=#restaurant-query-processing-example>#</a></h2><h3 id=real-system-flow-i-am-planning-to-have-dinner-at-teleferic-barcelona-in-los-gatos-tonight---what-should-i-eat-to-stay-under-1000-calories-get-60-grams-of-protein-and-15-gms-fiber>Real System Flow: &ldquo;I am planning to have dinner at Teleferic Barcelona in Los Gatos tonight - what should I eat to stay under 1000 calories, get 60 grams of protein and 15 gms fiber&rdquo;<a hidden class=anchor aria-hidden=true href=#real-system-flow-i-am-planning-to-have-dinner-at-teleferic-barcelona-in-los-gatos-tonight---what-should-i-eat-to-stay-under-1000-calories-get-60-grams-of-protein-and-15-gms-fiber>#</a></h3><p>Here is what actually happens with a real example. Suppose you say: “I’m planning dinner at Teleferic Barcelona in Los Gatos—keep me under 1,000 calories with 60g protein and 15g fiber. What should I order?”</p><h4 id=step-1-understand-the-request-and-pick-a-tool>Step 1: Understand the request and pick a tool<a hidden class=anchor aria-hidden=true href=#step-1-understand-the-request-and-pick-a-tool>#</a></h4><p>The agent parses your message and recognizes it as a restaurant request. Using OpenAI’s “function calling” ability, it selects our <code>search_restaurant_menu</code> tool to find current menu items that match your goals. In code, this selection happens in <code>UnifiedJarvisAgent.process_message_stream()</code> and the function itself is defined in <code>_define_functions()</code>.</p><h4 id=step-2-show-progress-right-away>Step 2: Show progress right away<a hidden class=anchor aria-hidden=true href=#step-2-show-progress-right-away>#</a></h4><p>Before the network request even finishes, the system streams a small token like &ldquo;SEARCHING_WEB_ANIMATION&rdquo; to the UI. That way, you immediately see that Jarvis is working, instead of staring at a blank screen.</p><h4 id=step-3-run-the-restaurant-search>Step 3: Run the restaurant search<a hidden class=anchor aria-hidden=true href=#step-3-run-the-restaurant-search>#</a></h4><p>The agent enriches your query with your calorie, protein, and fiber targets, then calls a helper (<code>get_restaurant_web_search</code>) that performs a web search for current menu details.</p><h4 id=step-4-use-the-web-responsibly>Step 4: Use the web responsibly<a hidden class=anchor aria-hidden=true href=#step-4-use-the-web-responsibly>#</a></h4><p>The web search helper builds a clear, structured prompt so the model knows exactly what to retrieve and how to format the results:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>search_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>Find current menu items and nutrition info for </span><span class=si>{</span><span class=n>restaurant_name</span><span class=si>}</span><span class=s1> that match: </span><span class=si>{</span><span class=n>query</span><span class=si>}</span><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>Focus on:
</span></span></span><span class=line><span class=cl><span class=s1>- 3-5 specific menu items with calorie/protein info
</span></span></span><span class=line><span class=cl><span class=s1>- Healthy options that meet dietary goals
</span></span></span><span class=line><span class=cl><span class=s1>- Include source links for each recommendation
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>Format: &#34;Item name ([source](url)) - calories, protein&#34;
</span></span></span><span class=line><span class=cl><span class=s1>Keep response concise.
</span></span></span><span class=line><span class=cl><span class=s1>&#39;&#39;&#39;</span>
</span></span></code></pre></div><p>It then calls OpenAI’s Responses API with the web search tool enabled, which lets the model use a browser‑like capability to gather live information:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>responses</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nb>input</span><span class=o>=</span><span class=n>search_prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=o>=</span><span class=p>[{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;web_search&#34;</span><span class=p>}]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h4 id=step-5-draft-and-stream-the-answer>Step 5: Draft and stream the answer<a hidden class=anchor aria-hidden=true href=#step-5-draft-and-stream-the-answer>#</a></h4><p>Once results come back, the agent weaves them into a short, friendly recommendation that cites sources. It streams the answer piece by piece so you can start reading without delay.</p><p>In conclusion, for this particular prompt, the data flow through the diagram is as follows: query => main agent loop => restaurant menu function => main agent loop => response.</p><p><strong>Code Locations:</strong></p><ul><li>Query processing: <code>django_backend/health_api/unified_agent.py</code> lines 284-404</li><li>Restaurant search: <code>django_backend/health_api/rag_service.py</code> lines 458-500</li><li>Function definitions: <code>django_backend/health_api/unified_agent.py</code> lines 86-110</li><li>Animation system: <code>django_backend/health_api/unified_agent.py</code> lines 714-728</li></ul><h2 id=comprehensive-test-suite>Comprehensive Test Suite<a hidden class=anchor aria-hidden=true href=#comprehensive-test-suite>#</a></h2><p><strong>Code Locations:</strong></p><ul><li>Main test file: <code>django_backend/test_unified_agent_functions.py</code></li><li>Test suite interface: <code>django_backend/templates/admin/test_suite.html</code></li></ul><h3 id=overview-1>Overview<a hidden class=anchor aria-hidden=true href=#overview-1>#</a></h3><p>We test Jarvis end‑to‑end using the same streaming pipeline the app uses in production. That means our tests are realistic: the agent calls the same functions, touches the same database, and produces the same kind of streaming messages users see. We don’t lock tests to a single “perfect” sentence—because language can vary—but we do check that the right functions run, data is saved correctly, and the final response reads sensibly. Specifically, we check response length, whether it RAGs and if so whether the category was correct, whether it logged food, and whether the ripple animation text was correct (which indicates whether the correct function was used).</p><p>The reason this is useful is because we have a set of behaviors we want Jarvis to adhere to, and at any time, we can run all of the tests to make sure that Jarvis does behave correctly. The test suite can also help with test-driven development. The test suite page is accessible at <code>/system/admin/test-suite</code>.</p><h3 id=test-architecture>Test Architecture<a hidden class=anchor aria-hidden=true href=#test-architecture>#</a></h3><p>Our main test file is <code>django_backend/test_unified_agent_functions.py</code>. Tests instantiate the real agent with streaming turned on. They operate against the same PostgreSQL database schema, but with isolated test users and session flags so no test runs pollute real chat history. Authentication uses dedicated accounts that mirror production, keeping the flow realistic.</p><h3 id=test-categories>Test Categories<a hidden class=anchor aria-hidden=true href=#test-categories>#</a></h3><p>We cover both one‑shot prompts and longer conversations.</p><h4 id=1-singleprompt-function-checks>1) Single‑prompt function checks<a hidden class=anchor aria-hidden=true href=#1-singleprompt-function-checks>#</a></h4><p>These tests send simple messages to validate each tool end to end. Examples include:</p><ul><li>Food logging: “I ate 2 eggs and bacon for breakfast.”</li><li>Weight tracking: “I weigh 155 pounds today.”</li><li>Health information: “Tell me about the benefits of omega‑3.”</li><li>Profile updates: “Update my weight goal to gain muscle.”</li></ul><h4 id=2-multiturn-conversations>2) Multi‑turn conversations<a hidden class=anchor aria-hidden=true href=#2-multiturn-conversations>#</a></h4><p>These tests exercise memory and context. We simulate:</p><ul><li>Progressive food logging across a day, making sure totals add up.</li><li>Health consultation flows with follow‑up questions and clarifications.</li><li>Recipe recommendation chains that move from preferences to concrete dishes.</li><li>Restaurant analysis that starts from location, narrows by cuisine, and ends with specific items.</li></ul><h3 id=test-execution-process>Test Execution Process<a hidden class=anchor aria-hidden=true href=#test-execution-process>#</a></h3><h4 id=step-1-start-an-isolated-session>Step 1: Start an isolated session<a hidden class=anchor aria-hidden=true href=#step-1-start-an-isolated-session>#</a></h4><p>Each test creates a unique session tied to a designated test user so data stays separate from real users:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Each test creates isolated session</span>
</span></span><span class=line><span class=cl><span class=n>test_user</span> <span class=o>=</span> <span class=n>User</span><span class=o>.</span><span class=n>objects</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>username</span><span class=o>=</span><span class=s1>&#39;test_user_agent_functions&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>session_id</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;test_session_</span><span class=si>{</span><span class=nb>int</span><span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>())</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span></code></pre></div><h4 id=step-2-talk-to-the-real-streaming-endpoint>Step 2: Talk to the real streaming endpoint<a hidden class=anchor aria-hidden=true href=#step-2-talk-to-the-real-streaming-endpoint>#</a></h4><p>Rather than calling internal functions directly, tests hit the same streaming HTTP endpoint the app uses. That keeps behavior honest:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=s1>&#39;http://localhost:5000/api/chat/stream/&#39;</span><span class=p>,</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;message&#39;</span><span class=p>:</span> <span class=n>test_message</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;user_id&#39;</span><span class=p>:</span> <span class=n>test_user</span><span class=o>.</span><span class=n>id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;session_id&#39;</span><span class=p>:</span> <span class=n>session_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;test_mode&#39;</span><span class=p>:</span> <span class=kc>True</span>  <span class=c1># Flags as test chat</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span></code></pre></div><h4 id=step-3-check-that-the-right-things-happened>Step 3: Check that the right things happened<a hidden class=anchor aria-hidden=true href=#step-3-check-that-the-right-things-happened>#</a></h4><p>We verify that the expected function ran, that any database side effects (like new food entries) exist, and that the response reads clearly. Error paths are exercised too, to confirm the system fails gracefully and recovers.</p><h3 id=test-data-validation>Test Data Validation<a hidden class=anchor aria-hidden=true href=#test-data-validation>#</a></h3><h4 id=database-verification>Database verification<a hidden class=anchor aria-hidden=true href=#database-verification>#</a></h4><p>Where a test implies a write—like logging food—we assert the database really changed:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Example: Food logging test verification</span>
</span></span><span class=line><span class=cl><span class=n>food_entries</span> <span class=o>=</span> <span class=n>DailyFoodLog</span><span class=o>.</span><span class=n>objects</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=n>user</span><span class=o>=</span><span class=n>test_user</span><span class=p>,</span> <span class=n>date</span><span class=o>=</span><span class=n>today</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>food_entries</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=k>assert</span> <span class=nb>any</span><span class=p>(</span><span class=s1>&#39;eggs&#39;</span> <span class=ow>in</span> <span class=n>entry</span><span class=o>.</span><span class=n>food_name</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=k>for</span> <span class=n>entry</span> <span class=ow>in</span> <span class=n>food_entries</span><span class=p>)</span>
</span></span></code></pre></div><h3 id=multi-prompt-test-examples>Multi-Prompt Test Examples<a hidden class=anchor aria-hidden=true href=#multi-prompt-test-examples>#</a></h3><h4 id=health-consultation-flow>Health consultation flow<a hidden class=anchor aria-hidden=true href=#health-consultation-flow>#</a></h4><ol><li>Initial context: “I have diabetes and high blood pressure.”</li><li>Follow‑up: “What breakfast foods should I avoid?”</li><li>Clarification: “Is oatmeal okay for my conditions?”</li><li>Expectation: The agent carries context across turns and tailors advice.</li></ol><h4 id=restaurant-analysis-chain>Restaurant analysis chain<a hidden class=anchor aria-hidden=true href=#restaurant-analysis-chain>#</a></h4><ol><li>Location: “I’m near downtown San Francisco.”</li><li>Preference: “I want healthy Mexican food.”</li><li>Goal: “Under 600 calories with high protein.”</li><li>Expectation: The agent respects location and cuisine while meeting nutrition targets.</li></ol><h3 id=test-isolation-and-cleanup>Test Isolation and Cleanup<a hidden class=anchor aria-hidden=true href=#test-isolation-and-cleanup>#</a></h3><h4 id=session-management>Session management<a hidden class=anchor aria-hidden=true href=#session-management>#</a></h4><p>All test chats set <code>test_mode=True</code>, which hides them from normal history views and flags them for cleanup. Temporary session IDs prevent collisions.</p><h4 id=data-isolation>Data isolation<a hidden class=anchor aria-hidden=true href=#data-isolation>#</a></h4><p>We use dedicated test users and tagging so it’s easy to find and remove any artifacts. This separation protects production data and keeps tests deterministic.</p><h3 id=performance-testing>Performance Testing<a hidden class=anchor aria-hidden=true href=#performance-testing>#</a></h3><p>We measure not just whether Jarvis answers, but how quickly and reliably it does so. Streaming tests track how fast chunks arrive. Database tests time common operations to catch slow queries. Memory tests check that the conversation window stays bounded. Finally, we simulate multiple users at once to make sure the system remains stable under load.</p><h3 id=test-reporting>Test Reporting<a hidden class=anchor aria-hidden=true href=#test-reporting>#</a></h3><p>Our reports summarize pass rates, response quality checks, and correctness of side effects (like accurate database writes). We include timing data and resource usage to spot regressions early, and we keep detailed error logs to speed up debugging when something breaks.</p><h3 id=real-world-simulation>Real-World Simulation<a hidden class=anchor aria-hidden=true href=#real-world-simulation>#</a></h3><p>We write tests in the same everyday language people use and deliberately switch topics mid‑conversation to verify Jarvis keeps up. We feed it unclear or contradictory inputs to test recovery, and we include edge cases that are uncommon but realistic. The result is a test suite that mirrors real usage, not just happy‑path demos.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://jiming-chen.github.io/>Jiming Chen</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>