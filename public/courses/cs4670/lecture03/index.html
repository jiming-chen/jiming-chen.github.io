<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Lecture 3: More Convolution | Jiming Chen</title><meta name=keywords content><meta name=description content="Convolution
The below filter for a pixel if the pixels to the bottom left are light and the pixels to the top right are dark, so it detects edges.

Fig. 1. An edge-detecting filter.
Shift equivariance is an important property, and it is why convolution is so used in the real world (including in machine learning). If we have a filter that detects cats, it should not break if the cat moves."><meta name=author content="Jiming Chen"><link rel=canonical href=https://jiming-chen.github.io/courses/cs4670/lecture03/><link crossorigin=anonymous href=/assets/css/stylesheet.d20d31710e1e17ede7c7f9ededb138159f9228abc86b338e8d1053ed139865b7.css integrity="sha256-0g0xcQ4eF+3nx/nt7bE4FZ+SKKvIazOOjRBT7ROYZbc=" rel="preload stylesheet" as=style><link rel=icon href=https://jiming-chen.github.io/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jiming-chen.github.io/icons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jiming-chen.github.io/icons/favicon-32x32.png><link rel=apple-touch-icon href=https://jiming-chen.github.io/icons/apple-touch-icon.png><link rel=mask-icon href=https://jiming-chen.github.io/%3C/icons/apple-touch-icon.png%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://jiming-chen.github.io/courses/cs4670/lecture03/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KTD621L9T6"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KTD621L9T6")</script><meta property="og:url" content="https://jiming-chen.github.io/courses/cs4670/lecture03/"><meta property="og:site_name" content="Jiming Chen"><meta property="og:title" content="Lecture 3: More Convolution"><meta property="og:description" content="Convolution The below filter for a pixel if the pixels to the bottom left are light and the pixels to the top right are dark, so it detects edges.
Fig. 1. An edge-detecting filter. Shift equivariance is an important property, and it is why convolution is so used in the real world (including in machine learning). If we have a filter that detects cats, it should not break if the cat moves."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="courses"><meta property="article:published_time" content="2025-01-27T13:29:37-05:00"><meta property="article:modified_time" content="2025-01-27T13:29:37-05:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lecture 3: More Convolution"><meta name=twitter:description content="Convolution
The below filter for a pixel if the pixels to the bottom left are light and the pixels to the top right are dark, so it detects edges.

Fig. 1. An edge-detecting filter.
Shift equivariance is an important property, and it is why convolution is so used in the real world (including in machine learning). If we have a filter that detects cats, it should not break if the cat moves."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Course Notes","item":"https://jiming-chen.github.io/courses/"},{"@type":"ListItem","position":2,"name":"CS 4670: Intro to Computer Vision","item":"https://jiming-chen.github.io/courses/cs4670/"},{"@type":"ListItem","position":3,"name":"Lecture 3: More Convolution","item":"https://jiming-chen.github.io/courses/cs4670/lecture03/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Lecture 3: More Convolution","name":"Lecture 3: More Convolution","description":"Convolution The below filter for a pixel if the pixels to the bottom left are light and the pixels to the top right are dark, so it detects edges.\nFig. 1. An edge-detecting filter. Shift equivariance is an important property, and it is why convolution is so used in the real world (including in machine learning). If we have a filter that detects cats, it should not break if the cat moves.\n","keywords":[],"articleBody":"Convolution The below filter for a pixel if the pixels to the bottom left are light and the pixels to the top right are dark, so it detects edges.\nFig. 1. An edge-detecting filter. Shift equivariance is an important property, and it is why convolution is so used in the real world (including in machine learning). If we have a filter that detects cats, it should not break if the cat moves.\nConvolution has the following properties:\nLinearity. Shift equivariance. Commutativity: $w*f=f*w$. Associativity. We can prove commutativity:\n$$(w*f)(m,n) = \\sum_i\\sum_j w(i,j)f(m-i,n-j).$$\nIf we let $i = m-i^\\prime$, and $j = n-j^\\prime$, then\n$$\\begin{aligned} (w*f)(m,n) \u0026= \\sum_{i^\\prime}\\sum_{j^\\prime} w(m-i^\\prime,n-j^\\prime)f(i^\\prime,j^\\prime) \\\\ \u0026= \\sum_{i^\\prime}\\sum_{j^\\prime}f(i^\\prime,j^\\prime) w(m-i^\\prime,n-j^\\prime) \\\\ \u0026= (f*w)(m,n). \\end{aligned}$$\nOne problem with the mean filter is that it assumes that all pixels in the neighborhood influence the pixel in question more. Therefore, we should weigh the nearer pixels to the pixel in question more. This motivates the Gaussian filter:\n$$G_\\sigma(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{x^2}{2\\sigma^2}},\\quad G_\\sigma(x,y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{x^2+y^2}{2\\sigma^2}}.$$\nWe ignore the coefficient in front of the exponential and instead normalize the filter so that each square adds to $1$. Note that increasing $\\sigma$ blurs the image more.\nOne thing we can do is take multiple Gaussians with different $\\sigma$ values and subtract them, and this can help us detect various structures at different scales (e.g. the overall facial structure vs. the wrinkles).\nWhat is the time complexity of convolution? If images are $w\\times h$ and the filter is $k\\times k$, then assuming “same” convolution, then there are $O(whk^2)$ operations. Assuming “full” convolution, then there are $O((w+k-1)(h+k-1)k^2)$ total operations. Regardless, the time complexity is $O(whk^2)$. This can be worrisome if $k$ is large.\nOf course, we can make convolution faster. One optimization to make is to use separable filters (singular value decomposition). If $w = u*v$, then we can apply $v$ first then $u$. Since $v$ is $1\\times k$ and $u$ is $k\\times1$, each pixel only needs $O(k)$ operations, so the time complexity becomes $O(whk)$.\nQuiz question: Which operation is the result of a convolution? Rotation, rgb2gray, scaling, or blurring?\nAnswer: Rgb2gray and blurring.\nRotation cannot be implemented using convolution because what the filter does must be different based on where the pixel is, which is not what convolution does.\nCan we do convolution as explicit matrix multiplication? Yes. For the 1-dimensional convolution for the row of pixels $0,0,0,90,90,90,90,90,0,0$ with filter $1/3,1/3,1/3$, we can multiply the original row of pixels (as a vector) by\n$$\\begin{bmatrix} 1/3 \u0026 1/3 \u0026 1/3 \u0026 0 \u0026 0 \u0026 \\cdots \\\\ 0 \u0026 1/3 \u0026 1/3 \u0026 1/3 \u0026 0 \u0026 \\cdots \\\\ \\vdots \u0026 \u0026 \u0026 \u0026 \u0026 \\ddots \\end{bmatrix}$$\nThis is a sparse matrix, so we can perform this calculation efficiently.\n","wordCount":"451","inLanguage":"en","datePublished":"2025-01-27T13:29:37-05:00","dateModified":"2025-01-27T13:29:37-05:00","author":{"@type":"Person","name":"Jiming Chen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jiming-chen.github.io/courses/cs4670/lecture03/"},"publisher":{"@type":"Organization","name":"Jiming Chen","logo":{"@type":"ImageObject","url":"https://jiming-chen.github.io/icons/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jiming-chen.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://jiming-chen.github.io/icons/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://jiming-chen.github.io/about title="About Me"><span>About Me</span></a></li><li><a href=https://jiming-chen.github.io/projects/ title=Portfolio><span>Portfolio</span></a></li><li><a href=https://jiming-chen.github.io/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://jiming-chen.github.io/courses/ title="Course Notes"><span>Course Notes</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Lecture 3: More Convolution</h1><div class=post-meta><span title='2025-01-27 13:29:37 -0500 EST'>January 27, 2025</span>&nbsp;·&nbsp;Jiming Chen</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#convolution>Convolution</a></li></ul></nav></div></details></div><div class=post-content><h2 id=convolution>Convolution<a hidden class=anchor aria-hidden=true href=#convolution>#</a></h2><p>The below filter for a pixel if the pixels to the bottom left are light and the pixels to the top right are dark, so it detects edges.</p><img src=/courses/cs4670/lecture03/edge.png alt="Edge filter" width=80% class=center><figcaption>Fig. 1. An edge-detecting filter.</figcaption><p>Shift equivariance is an important property, and it is why convolution is so used in the real world (including in machine learning). If we have a filter that detects cats, it should not break if the cat moves.</p><p>Convolution has the following properties:</p><ul><li>Linearity.</li><li>Shift equivariance.</li><li>Commutativity: $w*f=f*w$.</li><li>Associativity.</li></ul><p>We can prove commutativity:</p><p>$$(w*f)(m,n) = \sum_i\sum_j w(i,j)f(m-i,n-j).$$</p><p>If we let $i = m-i^\prime$, and $j = n-j^\prime$, then</p><p>$$\begin{aligned}
(w*f)(m,n) &= \sum_{i^\prime}\sum_{j^\prime} w(m-i^\prime,n-j^\prime)f(i^\prime,j^\prime) \\
&= \sum_{i^\prime}\sum_{j^\prime}f(i^\prime,j^\prime) w(m-i^\prime,n-j^\prime) \\
&= (f*w)(m,n).
\end{aligned}$$</p><p>One problem with the mean filter is that it assumes that all pixels in the neighborhood influence the pixel in question more. Therefore, we should weigh the nearer pixels to the pixel in question more. This motivates the Gaussian filter:</p><p>$$G_\sigma(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2}{2\sigma^2}},\quad G_\sigma(x,y) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{x^2+y^2}{2\sigma^2}}.$$</p><p>We ignore the coefficient in front of the exponential and instead normalize the filter so that each square adds to $1$. Note that increasing $\sigma$ blurs the image more.</p><p>One thing we can do is take multiple Gaussians with different $\sigma$ values and subtract them, and this can help us detect various structures at different scales (e.g. the overall facial structure vs. the wrinkles).</p><p>What is the time complexity of convolution? If images are $w\times h$ and the filter is $k\times k$, then assuming &ldquo;same&rdquo; convolution, then there are $O(whk^2)$ operations. Assuming &ldquo;full&rdquo; convolution, then there are $O((w+k-1)(h+k-1)k^2)$ total operations. Regardless, the time complexity is $O(whk^2)$. This can be worrisome if $k$ is large.</p><p>Of course, we can make convolution faster. One optimization to make is to use separable filters (singular value decomposition). If $w = u*v$, then we can apply $v$ first then $u$. Since $v$ is $1\times k$ and $u$ is $k\times1$, each pixel only needs $O(k)$ operations, so the time complexity becomes $O(whk)$.</p><blockquote><p><strong>Quiz question</strong>: Which operation is the result of a convolution? Rotation, rgb2gray, scaling, or blurring?</p></blockquote><blockquote><p><strong>Answer</strong>: Rgb2gray and blurring.</p></blockquote><p>Rotation cannot be implemented using convolution because what the filter does must be different based on where the pixel is, which is not what convolution does.</p><p>Can we do convolution as explicit matrix multiplication? Yes. For the 1-dimensional convolution for the row of pixels $0,0,0,90,90,90,90,90,0,0$ with filter $1/3,1/3,1/3$, we can multiply the original row of pixels (as a vector) by</p><p>$$\begin{bmatrix}
1/3 & 1/3 & 1/3 & 0 & 0 & \cdots \\
0 & 1/3 & 1/3 & 1/3 & 0 & \cdots \\
\vdots & & & & & \ddots
\end{bmatrix}$$</p><p>This is a sparse matrix, so we can perform this calculation efficiently.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://jiming-chen.github.io/>Jiming Chen</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>